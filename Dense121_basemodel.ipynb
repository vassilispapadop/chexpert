{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use(\"Agg\") # set the matplotlib backend so figures can be saved in the background\n",
    " \n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(p):\n",
    "    '''read from configuration file'''\n",
    "    with open(p) as f:\n",
    "        d = json.load(f)\n",
    "    \n",
    "    #fix trailing slash\n",
    "    if(d['df'][-1] != '/'):\n",
    "        d['df'] += '/'\n",
    "    \n",
    "    print(\"path: \", d['df'])\n",
    "    print(\"train labels\", d['train_labels'])\n",
    "    print(\"test_labels\", d['test_labels'])\n",
    "    print(\"features\", d['features']),\n",
    "    print(\"processing features\", d['process_features'])\n",
    "    return d['df'], d['train_labels'], d['test_labels'], d['features'], d['process_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  CheXpert-v1.0-small/\n",
      "train labels train.csv\n",
      "test_labels valid.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7e00cf184fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_col'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_col'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnumber_of_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-caff3c2a5306>\u001b[0m in \u001b[0;36mread_config\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processing features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'process_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'process_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "[df_path, train_labels, test_labels, features, processing_features] = read_config('config.json')\n",
    "x_col = processing_features['x_col']\n",
    "y_col = processing_features['y_col']\n",
    "number_of_features = len(y_col)\n",
    "\n",
    "# import train data info from valid.csv\n",
    "dtrain=pd.read_csv(df_path + train_labels, nrows=100)\n",
    "dtrain = dtrain.fillna(0)\n",
    "\n",
    "# import valid data info from valid.csv\n",
    "dnew=pd.read_csv(df_path + test_labels)\n",
    "dnew = dnew.fillna(0)\n",
    "\n",
    "#add dnew to dtrain to re-split since valid data in data set is very small\n",
    "dtrain = dtrain.append(dnew)\n",
    "\n",
    "#pre-process data: remove Lateral images\n",
    "dtrain = dtrain[~dtrain[dtrain.columns[3]].str.contains(\"Lateral\")]\n",
    "\n",
    "#pre-process data: drop selected features - only images as inputs\n",
    "#drop all features that are not included in processing_features\n",
    "to_drop = list(set(features) - set(y_col))\n",
    "to_drop.remove(x_col)\n",
    "print('dropping columns....\\n', to_drop)\n",
    "dtrain = dtrain.drop(to_drop, axis=1)\n",
    "\n",
    "#uncertain examples make them positive\n",
    "dtrain = dtrain.replace(-1,1)\n",
    "\n",
    "dtrain.drop(dtrain.loc[(dtrain['Pneumonia'] == 0) & (dtrain['No Finding'] == 0) & (dtrain['Lung Lesion'] == 0)].index, inplace=True)\n",
    "\n",
    "\n",
    "# print(dtrain.shape)\n",
    "# dtrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No Finding', 'Pneumonia', 'Lung Lesion']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = plt.imread('pic.jpg')\n",
    "# show the image\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "features_size=[]\n",
    "features_data =[]\n",
    "features_name=[]\n",
    "#print(list(dtrain.columns[1:15]))\n",
    "for feature in list(dtrain.columns[1:4]):\n",
    "    data_feature = dtrain.loc[dtrain[feature] == 1]\n",
    "    features_size.append(data_feature.shape[0])\n",
    "    features_data.append(data_feature)\n",
    "    features_name.append(feature)\n",
    "\n",
    "objects = list(dtrain.columns[1:4])\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = np.array(features_size)/dtrain.shape[0]*100\n",
    "# print(features_data)\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('% of positive label per observation')\n",
    "plt.title('Data Distribution')\n",
    "plt.show()\n",
    "plt.savefig('DataDistribute.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35578, 4)\n",
      "(4448, 4)\n",
      "(4447, 4)\n"
     ]
    }
   ],
   "source": [
    "### split data into train/valid/test\n",
    "dtrain = dtrain.sample(frac=1)\n",
    "dvalid_size = round(0.1*dtrain.shape[0])\n",
    "dtest_size = dvalid_size\n",
    "\n",
    "dtr = dtrain[0:dtrain.shape[0]-dvalid_size-dtest_size+1]\n",
    "dv = dtrain[dtrain.shape[0]-dvalid_size-dtest_size:dtrain.shape[0]-dvalid_size+1]\n",
    "dte = dtrain[dtrain.shape[0]-dvalid_size:dtrain.shape[0]+1]\n",
    "\n",
    "print(dtr.shape)\n",
    "print(dv.shape)\n",
    "print(dte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35578 validated image filenames.\n",
      "Found 4448 validated image filenames.\n",
      "Found 4447 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "### data generation for Keras \n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "valid_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "# target_size = (224,224)\n",
    "#target_size = (299,299)\n",
    "target_size = (75,75)\n",
    "train_generator=train_datagen.flow_from_dataframe(dataframe=dtr, directory=None , \n",
    "                                                  x_col=\"Path\", y_col=list(dtr.columns[1:3]), \n",
    "                                                  class_mode=\"other\", \n",
    "                                                  target_size=target_size, \n",
    "                                                  batch_size=32)\n",
    "valid_generator=valid_datagen.flow_from_dataframe(dataframe=dv, directory=None , \n",
    "                                                  x_col=\"Path\", y_col=list(dv.columns[1:3]), \n",
    "                                                  class_mode=\"other\", \n",
    "                                                  target_size=target_size, \n",
    "                                                  batch_size=32)\n",
    "test_generator=test_datagen.flow_from_dataframe(dataframe=dte, directory=None , \n",
    "                                                x_col=\"Path\", y_col=list(dte.columns[1:3]), \n",
    "                                                class_mode=\"other\", \n",
    "                                                target_size=target_size, \n",
    "                                                shuffle = False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model architecture design/selection\n",
    "# create the base pre-trained model\n",
    "base_model = DenseNet121(include_top = False, weights='imagenet')\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer\n",
    "predictions = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional DenseNet layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "\n",
    "#model training\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1111/1111 [==============================] - 829s 710ms/step - loss: 0.5635 - accuracy: 0.6409 - val_loss: 0.4950 - val_accuracy: 0.6178\n",
      "Epoch 2/3\n",
      "1111/1111 [==============================] - 602s 542ms/step - loss: 0.4928 - accuracy: 0.6371 - val_loss: 0.4939 - val_accuracy: 0.7003\n",
      "Epoch 3/3\n",
      "1111/1111 [==============================] - 545s 490ms/step - loss: 0.4801 - accuracy: 0.6510 - val_loss: 0.4988 - val_accuracy: 0.6012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### fit model \n",
    "num_epochs = 3\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "\n",
    "#Tensorboard\n",
    "log_dir = \"logs/fit/train\"# + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model_H = model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "# save model\n",
    "model.save(\"model_DenseNet121_TF_Binary.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my trained model \n",
    "model_F = load_model('model_DenseNet121_TF_Binary.h5')\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prediction and performance assessment\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "pred_bool = (pred >= 0.5)\n",
    "\n",
    "y_pred = np.array(pred_bool,dtype =int)\n",
    "\n",
    "dtest = dte.to_numpy()\n",
    "y_true = np.array(dtest[:,1:4],dtype=int)\n",
    "\n",
    "print(classification_report(y_true, y_pred,target_names=list(dtr.columns[1:4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
